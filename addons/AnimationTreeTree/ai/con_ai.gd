# spinalcord
# https://github.com/spinalcord/animation-tree-tree-godot
# 
# This file is part of animation-tree-tree-godot.
# 
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU Affero General Public.
#
# NOTE: The output generated by this addon is not affected by this license.

# ConAI.gd
class_name ConAI
extends RefCounted

enum Role
{
	System,
	User,
	Assistant,
	Tool
}
var http_request: HTTPRequest

var model: String = "local-model"
var temperature: float = 0.7
var max_tokens: int = 100000
var base_url: String = "http://localhost:1234"
## Prevents "Context Overflow" with "Sliding Window Algorithm". Affects only the API Message.
var context_window_slide_size: int = 15
var api_key: String = ""  # Add this line

func _init():
	
	# Load config values or use defaults
	model = AnimationTreeTree.plugin_config.get_value("settings", "model", "local-model")
	temperature = AnimationTreeTree.plugin_config.get_value("settings", "temperature", 0.7)
	max_tokens = AnimationTreeTree.plugin_config.get_value("settings", "max_tokens", 60000)
	base_url = AnimationTreeTree.plugin_config.get_value("settings", "base_url", "http://localhost:1234")
	context_window_slide_size = AnimationTreeTree.plugin_config.get_value("settings", "context_window_slide_size", 15)
	api_key = AnimationTreeTree.plugin_config.get_value("settings", "api_key", "") 

	http_request = HTTPRequest.new()
	if Engine.is_editor_hint():
		EditorInterface.get_base_control().add_child(http_request)

## Emitted when a tool is called with its name and arguments
signal tool_called(tool_name: String, arguments: Dictionary)
## Emitted when a tool execution is completed with its result
signal tool_result(tool_name: String, result: String)
## Emitted when the entire message process completed successfully
signal message_completed(conversation: Conversation)
## Emitted when any error occurs that prevents getting a final answer
signal message_error()
## Emitted when the dialog is force-closed by the user
signal dialog_cancelled()

var _is_cancelled: bool = false

# Main function to get an AI answer using Agent and Conversation
func answer(agent: Agent, conversation: Conversation, tools: ConAITool, message: String, debug_title: String = "") -> void:
	_is_cancelled = false
	TreeDebug.msg(debug_title + "Request ðŸ™‹: " + message)
	# Backup conversation state for rollback
	var backup_chain = conversation.chain.duplicate(true)
	var backup_timestamp_last = conversation.timestamp_last
	
	# Add user message to conversation
	conversation.add_message(message, Role.find_key(Role.User).to_lower())
	
	# Build message array: system prompt + conversation chain
	var msg_array: Array = []
	msg_array.append({"role": "system", "content": agent.system_prompt})
	msg_array.append_array(conversation.chain)
	
	# Apply sliding window if needed
	var truncated_messages = truncate_sliding_window(msg_array, context_window_slide_size)
	await _process_message(tools, truncated_messages, conversation, backup_chain, backup_timestamp_last)

## Internal function to process messages
func _process_message(tools: ConAITool, msg_array: Array, conversation: Conversation, backup_chain: Array, backup_timestamp_last: float) -> void:
	# Show progress dialog
	var feedback = FeedbackDialog.new()
	var progress_dialog = feedback.show_progress("Sending request to AI...", "Processing", false)
	
	var dialog_closed_by_user = false
	var on_dialog_hide = func():
		dialog_closed_by_user = true
		_is_cancelled = true
		dialog_cancelled.emit()
		TreeDebug.msg("âš ï¸ Dialog closed by user")
	
	if progress_dialog.has_signal("popup_hide"):
		progress_dialog.connect("popup_hide", on_dialog_hide)
	elif progress_dialog.has_signal("close_requested"):
		progress_dialog.connect("close_requested", on_dialog_hide)
	elif progress_dialog.has_signal("visibility_changed"):
		var on_visibility = func():
			if not progress_dialog.visible:
				on_dialog_hide.call()
		progress_dialog.connect("visibility_changed", on_visibility)
	
	var headers = ["Content-Type: application/json"]
	if api_key != "":
		headers.append("Authorization: Bearer " + api_key)
		TreeDebug.msg("ðŸ”‘ Using API Key authentication")
	else:
		TreeDebug.msg("âš ï¸ No API Key set - using local endpoint")
		
	var body = {
		"model": model,
		"messages": msg_array,
		"temperature": temperature,
		"max_tokens": max_tokens
	}
	
	# Add tools only if provided
	if tools != null:
		body["tools"] = tools.get_structure()
	
	# Smart endpoint building
	var endpoint_url = base_url
	if not endpoint_url.ends_with("/completions"):
		if endpoint_url.contains("/openai"):
			endpoint_url += "/chat/completions"
		else:
			endpoint_url += "/v1/chat/completions"
	
	TreeDebug.msg("ðŸ“¡ Endpoint: " + endpoint_url)
	TreeDebug.msg("ðŸ“¤ Sending request with model: " + model)
	
	http_request.request(endpoint_url, headers, HTTPClient.METHOD_POST, JSON.stringify(body))
	feedback.update_progress(progress_dialog, "Waiting for response...")
	
	var response = await http_request.request_completed
	
	if _is_cancelled or not is_instance_valid(progress_dialog) or not progress_dialog.visible:
		_is_cancelled = true
		if is_instance_valid(progress_dialog):
			feedback.close_progress(progress_dialog)
		conversation.chain = backup_chain
		conversation.timestamp_last = backup_timestamp_last
		TreeDebug.msg("âŒ Request cancelled by user")
		return
	
	var http_result = response[0]  # result code
	var response_code = response[1]  # HTTP response code
	var response_headers = response[2]  # headers
	var body_data = response[3]  # body
	
	TreeDebug.msg("ðŸ“¥ HTTP Result: " + str(http_result) + " | Response Code: " + str(response_code) )
	
	if http_result == HTTPRequest.Result.RESULT_SUCCESS and response_code == 200:
		feedback.update_progress(progress_dialog, "Processing response...")
		
		var json = JSON.new()
		json.parse(body_data.get_string_from_utf8())
		var jsonObj: Dictionary = json.data
		var choice = jsonObj["choices"][0]
		
		if choice["finish_reason"] == "length":
			feedback.close_progress(progress_dialog)
			# Rollback conversation on error
			conversation.chain = backup_chain
			conversation.timestamp_last = backup_timestamp_last
			message_error.emit()
			assert(false, "Response was truncated by the endpoint! Increase max_tokens.")
			return
			
		choice = choice["message"]
		
		var content: String = choice["content"] if choice.has("content") and choice["content"] != null else ""
		var has_tools_field: bool = choice.has("tool_calls") and choice["tool_calls"] != null
		
		var tool_calls: Array = []
		if has_tools_field:
			tool_calls = choice["tool_calls"]
		
		var need_tool_request: bool = tool_calls.size() > 0 and tools != null
		
		if need_tool_request:
			if _is_cancelled or not is_instance_valid(progress_dialog) or not progress_dialog.visible:
				_is_cancelled = true
				if is_instance_valid(progress_dialog):
					feedback.close_progress(progress_dialog)
				conversation.chain = backup_chain
				conversation.timestamp_last = backup_timestamp_last
				TreeDebug.msg("âŒ Request cancelled by user")
				return
			
			feedback.update_progress(progress_dialog, "Executing tools...")
			
			# Add the assistant message with tool calls to the messages
			var assistant_message = {
				"role": "assistant",
				"tool_calls": tool_calls
			}
			msg_array.append(assistant_message)
			conversation.chain.append(assistant_message)
			
			# Execute all tool calls
			for tool_call in tool_calls:
				if _is_cancelled or not is_instance_valid(progress_dialog) or not progress_dialog.visible:
					_is_cancelled = true
					if is_instance_valid(progress_dialog):
						feedback.close_progress(progress_dialog)
					conversation.chain = backup_chain
					conversation.timestamp_last = backup_timestamp_last
					TreeDebug.msg("âŒ Request cancelled by user")
					return
				
				var tool_id = tool_call["id"]
				var function_name = tool_call["function"]["name"]
				var arguments_str = tool_call["function"]["arguments"]
				var arguments_dict = JSON.parse_string(arguments_str)
				
				TreeDebug.msg("Use Tool ðŸ”§: " + function_name)
				feedback.update_progress(progress_dialog, "Using tool: " + function_name)
				
				tool_called.emit(function_name, arguments_dict)
				
				# Execute the tool
				var result = tools.call_tool(function_name, arguments_dict)
				
				tool_result.emit(function_name, result)
				
				# Add tool result to messages
				var tool_message = {
					"role": "tool",
					"content": str(result),
					"tool_call_id": tool_id
				}
				msg_array.append(tool_message)
				conversation.chain.append(tool_message)
			
			if _is_cancelled or not is_instance_valid(progress_dialog) or not progress_dialog.visible:
				_is_cancelled = true
				if is_instance_valid(progress_dialog):
					feedback.close_progress(progress_dialog)
				conversation.chain = backup_chain
				conversation.timestamp_last = backup_timestamp_last
				TreeDebug.msg("âŒ Request cancelled by user")
				return
			
			# Make a new request with the tool results
			feedback.update_progress(progress_dialog, "Getting final response...")
			
			var tool_body = {
				"model": model,
				"messages": msg_array,
				"temperature": temperature,
				"max_tokens": max_tokens
			}
			
			http_request.request(endpoint_url, headers, HTTPClient.METHOD_POST, JSON.stringify(tool_body))
			var tool_response = await http_request.request_completed
			
			if _is_cancelled or not is_instance_valid(progress_dialog) or not progress_dialog.visible:
				_is_cancelled = true
				if is_instance_valid(progress_dialog):
					feedback.close_progress(progress_dialog)
				conversation.chain = backup_chain
				conversation.timestamp_last = backup_timestamp_last
				TreeDebug.msg("âŒ Request cancelled by user")
				return
			
			var tool_http_result = tool_response[0]
			var tool_response_code = tool_response[1]
			var tool_response_headers = tool_response[2]
			var tool_body_data = tool_response[3]
			
			if tool_http_result == HTTPRequest.Result.RESULT_SUCCESS and tool_response_code == 200:
				var tool_json = JSON.new()
				tool_json.parse(tool_body_data.get_string_from_utf8())
				var tool_jsonObj: Dictionary = tool_json.data
				var tool_choice = tool_jsonObj["choices"][0]
				
				if tool_choice["finish_reason"] == "length":
					feedback.close_progress(progress_dialog)
					# Rollback conversation on error
					conversation.chain = backup_chain
					conversation.timestamp_last = backup_timestamp_last
					message_error.emit()
					assert(false, "Tool response was truncated! Increase max_tokens.")
					return
					
				tool_choice = tool_choice["message"]
				var final_content: String = tool_choice["content"]
				
				# Add the final answer to conversation
				conversation.add_message(final_content, "assistant")
				save_conversation(conversation, "user://conversations/chat.json")
				
				feedback.close_progress(progress_dialog)
				TreeDebug.msg("Response with Tool-Usage ðŸ¤–: " + final_content)
				message_completed.emit(conversation)
			else:
				feedback.close_progress(progress_dialog)
				# Rollback conversation on error
				conversation.chain = backup_chain
				conversation.timestamp_last = backup_timestamp_last
				TreeDebug.msg("Tool request failed. Status: ", tool_response_code)
				# Support for saving file, need that in other version iterations
				#save_conversation(conversation, "user://conversations/chat.json")
				message_error.emit()
		else:
			# Normal answer without tools
			conversation.add_message(content, "assistant")
			# Support for saving file, need that in other version iterations
			# save_conversation(conversation, "user://conversations/chat.json")
			
			feedback.close_progress(progress_dialog)
			message_completed.emit(conversation)
			
	else:
		# Important if we save our file to json.
		feedback.close_progress(progress_dialog)
		# Rollback conversation on error
		conversation.chain = backup_chain
		conversation.timestamp_last = backup_timestamp_last
		
		var failed_string: String = "âŒâŒâŒ ERROR: Request failed! âŒâŒâŒ\n"
		failed_string += "Response Code:" + str(http_result) + "\n"
		failed_string += "HTTP Result===========\n" + str(http_result) + "\n"
		failed_string += "Raw Response==========\n" + body_data.get_string_from_utf8() + "\n"
		
		var error_json = JSON.new()
		var parse_result = error_json.parse(body_data.get_string_from_utf8())
		if parse_result == OK and error_json.data != null:
			failed_string += "JSON Error==========\n" + str(error_json) + "\n"
		else:
			failed_string += "\nCould not parse error response\n"
			
		if !(error_json.data != null):
			failed_string += "POST===========\n" + "POST response was null, is the server running?" + "\n"
			
		feedback.show_text("Request failed!", "Request failed!", failed_string, true)
		
		message_error.emit()


###############################
## loading and saving
###############################
func save_conversation(conversation: Conversation, file_path: String) -> bool:
	if not conversation or conversation.chain.is_empty():
		push_warning("No conversation to save")
		return false
	
	# Erstelle Verzeichnis falls es nicht existiert
	var dir_path = file_path.get_base_dir()
	if not DirAccess.dir_exists_absolute(dir_path):
		DirAccess.open("user://").make_dir_recursive(dir_path.trim_prefix("user://"))
	
	# Speichere Conversation-Zustand
	var save_data = {
		"chain": conversation.chain,
		"timestamp_started": conversation.timestamp_started,
		"timestamp_last": conversation.timestamp_last
	}
	
	var file = FileAccess.open(file_path, FileAccess.WRITE)
	if not file:
		push_error("Could not open file for writing: " + file_path)
		return false
	
	var json_string = JSON.stringify(save_data, "\t")
	file.store_string(json_string)
	file.close()
	
	TreeDebug.msg("Conversation saved to: " + file_path + " (" + str(conversation.chain.size()) + " messages)")
	return true

func load_conversation(file_path: String) -> Conversation:
	if not FileAccess.file_exists(file_path):
		push_warning("Conversation file does not exist: " + file_path)
		return null
	
	var file = FileAccess.open(file_path, FileAccess.READ)
	if not file:
		push_error("Could not open file for reading: " + file_path)
		return null
	
	var json_string = file.get_as_text()
	file.close()
	
	var json = JSON.new()
	var parse_result = json.parse(json_string)
	
	if parse_result != OK:
		push_error("Failed to parse JSON from file: " + file_path)
		return null
	
	var data = json.data
	if not data is Dictionary:
		push_error("Invalid conversation format in file: " + file_path)
		return null
	
	var conversation = Conversation.new()
	conversation.chain = data.get("chain", [])
	conversation.timestamp_started = data.get("timestamp_started", 0.0)
	conversation.timestamp_last = data.get("timestamp_last", 0.0)
	
	TreeDebug.msg("Conversation loaded from: " + file_path + " (" + str(conversation.chain.size()) + " messages)")
	return conversation

###############################
## messages optimization
###############################

## Reduces the message array with sliding window algorithm.
func _on_dialog_cancelled() -> void:
	_is_cancelled = true
	dialog_cancelled.emit()
	TreeDebug.msg("âš ï¸ Dialog cancelled by user")

func truncate_sliding_window(target_messages: Array, window_size: int) -> Array:
	if target_messages.is_empty() or (window_size <= 0):
		return target_messages
	
	var result = []
	var system_role = Role.find_key(Role.System).to_lower()
	var user_role = Role.find_key(Role.User).to_lower()
	var assistant_role = Role.find_key(Role.Assistant).to_lower()
	
	var system_message = null
	for message in target_messages:
		if message.get("role", "") == system_role:
			system_message = message
			break
	
	if system_message:
		result.append(system_message)
	
	var first_user_message = null
	for message in target_messages:
		if message.get("role", "") == user_role:
			first_user_message = message
			break
	
	if first_user_message:
		result.append(first_user_message)
	
	var needs_truncation = target_messages.size() > (3 + window_size)
	
	var truncation_notice = null
	if needs_truncation:
		truncation_notice = {
			"role": assistant_role,
			"content": "[Conversation history truncated to maintain context window]"
		}
		result.append(truncation_notice)
	
	var non_system_messages = []
	for message in target_messages:
		if message.get("role", "") != system_role:
			non_system_messages.append(message)
	
	if first_user_message and non_system_messages.size() > 0 and non_system_messages[0] == first_user_message:
		non_system_messages = non_system_messages.slice(1)
	
	var recent_messages = non_system_messages.slice(-window_size) if non_system_messages.size() > window_size else non_system_messages
	
	while not recent_messages.is_empty() and recent_messages[-1].get("role", "") == assistant_role:
		recent_messages = recent_messages.slice(0, -1)
	
	result.append_array(recent_messages)
	
	if not result.is_empty():
		var final_message = result[-1]
		var final_role = final_message.get("role", "")
		if final_role == assistant_role and (not truncation_notice or final_message != truncation_notice):
			push_warning("Warning: Conversation flow ends with Assistant message - this may cause issues")
		else:
			var action = "retained" if not needs_truncation else "truncated successfully"
			TreeDebug.msg("Conversation " + action + ": " + str(result.size()) + " messages")
	
	return result


	
	
